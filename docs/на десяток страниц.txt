import mozg # не очень

1.0 Определения

    1.1 Для начала дам несколько опредений.

        Первое - что такое сам искусственный интеллект. Есть множество вариаций 
        определения в различных ситочниках. В википедии одно время было 
        закольцованное определение. Когда первое определние (ИИ) ссылается на 
        второе (например творчество), второе на третье (что-то филосовское), 
        третье снова на первое. Думаю, что у почти всех, кто знает про git уже 
        есть интуитивное определение.

    1.2 Второе - сильный ИИ. 

        Как ни трудно догадаться, есть еще слабый ИИ. Начнем с слабого. Про него 
        неоднократно писали в прессе, что нейросети опять чего-то натворили. Его 
        еще узким видимо называют. Тут прямо цитата. "Artificial Narrow 
        Intelligence (ANI): это ИИ специализирующийся на (удалить пробельчик) 
        конкретной задаче/проблеме. И, зачастую, превосходящий человека в 
        решении этой задачи. Например, шахматная программа обыграла человека, но 
        она умеет только это. Речь идёт о различного рода экспертных системах, 
        как правило, работающих с большими объёмами данных." Сильный - я 
        определение сам дам коряво, зато незазорно за каждое слово. Это 
        программа, обладающая рядом обязательных черт или свойств: память, 
        целеполагание, принятие решения, планирование, вывод новых знаний, 
        общение. Позже, допускаю, что могут быть добавлены черты или изменены 
        существующие, но пока так. Оять же есть множество источников, где его 
        пытаются дать. Его же иногда называют общим. Artificial General 
        Intelligence (AGI). Отсюда и название репы. Есть еще супер ии, но это 
        оставим фантастам.

2.0 Актуальность

    Сейчас существет много тел роботов, которые обладают достаточно продвинутой 
    механикой для решения общих задач. Но отсутвие сегмента программ сильного ии 
    не позволяет им выполнять эти задачи. Их программы часто базируются на 
    автоматах и не подразумевают большой изменичивости или дообучения не ходу.
    Посмотрим несколько примеров. Икона - Бостон динамикс, будь она неладна, 
    объявила о желании создания подразделения, занимающегося вопросами ии. Еще 
    раз констатировала, что атлас всего лишь научный инструмент и тацует по к 
    сожалению примитивной программе.
    https://www.youtube.com/watch?v=InvCCX4W8_Y
    Четкое выделение предметных областей пугает. Гугл evryday, понимает 
    сложность решения бытовых задачь и пытается собрать робота их решающих с 
    условием не переходя грань общесдоступных комплектующих.
    https://everydayrobots.com/
    Тоета еще пыталась делать антропоморфного помошника для дома. Но судя по 
    кадрам руки у него трясутся и методы там какие-нибудь обычные. Сильно много 
    приеров приводить не буду, т к очевидно, что проблема актуальна. Простят 
    меня за данный стиль повествования.

3.0 Текущие подходы их достоинства и недостатки.

    3.1 Нейросетевые методы.        
        Сразу окунемся в ближайшего околоаналога - нейронные сети. 
        Были рассмотерны эти статьи.
        https://habr.com/ru/post/468379/
        https://habr.com/ru/company/neurodatalab/blog/335238/
        https://habr.com/ru/post/437020/
        Есть несколько видов нейросетевых методов.
        Обучение с учителем. Часто применяется в классификации картинок.
        - Первый недостаток, который я выделю - наличие датасета. Его на текущий момент готовят люди. Не для всех предметных областей они есть.
        Большинство бытовых задачь уже понятно как делать и нужно только объяснить машине как их делать. 
        По крайней мере так мы поступаем с детьми. Человек учится на длине датасета 1 ну может быть 10. Датасеты однозначное зло.
        - Второе - невозможность вытащить сформулированные правила из обученной сети. У сверточных сетей с этим проще, т к на промежуточных картах активации
        можно увидеть, какие места на картинке оказались важными. Но карта активации - это даже не картинка. Это места, где фильтр свертки дал большие числа.
        На первых слоях будет белеберда - маленькие геометрические черты картинки.
        Забегая вперед, скажем, что понимать почему сеть принила то или иное реение - очень хочется, если не сказать жизненно необходимо, для дальнейшей настройки сети.
        Выделился термин - объяснимый ИИ. Вспоминается проект гугла.
        https://cloud.google.com/explainable-ai/
        Судя по картинке, они как раз показывают промежуточные слои, хотя, я сильно не вчитывался. Как минимум важен факт выделения термина, заинтерисованности гугла.
        Есть проекты изъятия правил из сети в виде математики. Это опять же предназначено для человека.
        Есть еще обучение без учителя. В нем я не сильно разбираюсь, но думаю, что ситуация схожа, как с другими типами сетей.
        Обучение с подкреплением. (Reinforcement Learning) 
        + Достоинством является то, что ему не нужен датасет. По сути он его на ходу собрает.
        В принципе, если бы человек учился неизвестному, то он бы тоже делел случайные ходы и смотрел чтоб будет.
        По сути RL это статистика.
        Процетирую некоторые выводы из статьи в частонсти для RL.
        - Медленная адаптация к изменяющемся условиям среды. 
        Тут, думаю, нужно оговриться, что адаптация есть, но она не достаточно быстрая, как того может требовать окружающий мир.
        С точки зрения аналитических методов у сетей наблюдается большая адаптивность.
        - Сложные модели требуют большого объема сетей. В статье, опять же, есть пример обчения тела ходьбе с 17 степенями свободы. 
        При увеличении степеней свободы, не получатется нормально обучить.
        Для анализа большой сети требуется еще большая сеть.
        - Не все сети могут крутить циклы.
        - Необходимо созадавть раздел или добавлять рекурентную сеть для учета предыдущих состояний.
        - Большая вычислительная сложность для определенных задачь. 
        - Непереносимость опыта из одной сети в другую. Есть медод, когда обученную сеть подключают на вход другой сети (transfer learning). 
        Перенос возможен только так.
        - Необходимо время на обученение. Часть опыта у людей передается по наследству, но это связано скорее с управлением организмом. 
        Часть передается с воспитанием и длится порядка 20 лет.
        С учетом накопленного опыта дообучение может происходить буквально в пару предложений.
        Перечисленные выводы по отдельности не фатальны, но в сумме подпекают.
        Общие свойства нейросетей.
        - Общая проблем состоит в необходимости длительного обучения. Есть вид обучения incremental learning. 
        Он подразумевает постоянно постоянно расширяющуюся модель при новых входных данных. Я не слышал об его болшом распространении.
        - Еще один недостаток - возможность переобучения. В большей степени касается больших стетей.
        - Обучать приходится сразу всем задачам. Иначе при дообучении веса перезапишутся под новую задачу.
        - Невозможность интеграции отдельных сетей в одну большую. Т к они имеют разные архитекуры, абсолютные значения весов, механизмов общего обучения.
        В статье, описывается предположение о том, чтобы сверточные для картинок, рекурентные для текста и обучение с подкреплением для генерации движений использовались вместе.
        Даже если ону сеть присоединяют  другой, то у одно из них, которая уже обучена веса замораживают.
        - Необходимость разработки архитектуры еще до начала обученя. 
        Допускаю, что есть проекты, где сеть конфигурирует архитектуру, но я не видел, чтобы они получили распространение.
        - Возможность ложного реагирования. Вытекает из невозможности просмотра вывода принятого решения.

    3.2 Логическое программирование.

    3.3 Нечеткая логика

    3.4 Генетические алгоритмы

    3.5 Статистические методы

    3.6 Ассоциативная память

    3.7 Выводы

        Мне достаточно было их факта существования, чтобы сделать выводы и забыть.
        


Предлагаемое решение

    графовый компьютер

    тз в предложение включить

    Посмотреть можно ли дополнить тз этими свойсвтами
    https://en.wikipedia.org/wiki/Artificial_general_intelligence
    https://ru.wikipedia.org/wiki/Сильный_и_слабый_искусственные_интеллекты