0.0 Целевая аудитория

    ???

1.0 Определение

    Существует классификация деления ИИ на сильный и слабый.
    Начнем со слабого. Его еще "узким" называют. Процитирую определение.
    "Artificial Narrow Intelligence (ANI): это ИИ специализирующийся на 
    конкретной задаче/проблеме. И, зачастую, превосходящий человека в 
    решении этой задачи. Например, шахматная программа обыграла человека, но 
    она умеет только это. Речь идёт о различного рода экспертных системах, 
    как правило, работающих с большими объёмами данных." Определние сильного ИИ. 
    Это программа, обладающая рядом обязательных черт или свойств: память, 
    целеполагание, принятие решения, планирование, вывод новых знаний, 
    общение. Позже, допускаю, что могут быть добавлены черты или изменены 
    существующие. Оять же есть множество источников, где его 
    пытаются дать. Его же иногда называют общим. Artificial General 
    Intelligence (AGI).

2.0 Актуальность

    Сейчас существет много тел роботов, которые обладают достаточно продвинутой 
    механикой для решения общих задач. Но отсутвие сегмента программ сильного ИИ 
    не позволяет им выполнять эти задачи. Их программы часто базируются на 
    автоматах и не подразумевают большой изменичивости или дообучения на ходу.
    Посмотрим несколько примеров. Бостон динамикс объявила о желании создания 
    подразделения, занимающегося вопросами ИИ. Еще раз констатировала, что 
    атлас всего лишь научный инструмент и тацует по заранее заложенной 
    программе. Четкое выделение предметных областей в будущей разработке, 
    скорей всего приведет к "слабому" ии.
    https://www.youtube.com/watch?v=InvCCX4W8_Y
    еще один пример. Проект google everyday. его создатели подчеркивают, как я 
    понял, сложность решения бытовых задачь. Они пытаются собрать робота из 
    общесдоступных комплектующих.
    https://everydayrobots.com/
    Многие другие компании (например toyota) пыталась делать антропоморфного 
    помошника для дома, но возможности этих роботв далеки от человека.
    Думаю, что проблема актуальна.

3.0 Текущие подходы

    Рассмотрим несколько методов приянтия решений в ИИ, их достоинства и недостатки.

    3.1 Нейросетевые методы
        Пояснять, как работают данные методы не буду в виду их популярности.
        Были рассмотерны статьи.
        https://habr.com/ru/post/468379/
        https://habr.com/ru/company/neurodatalab/blog/335238/
        https://habr.com/ru/post/437020/
        Достоинства.
        1) Отсутсвие датасета для определенных видов сетей. Касается обучения с 
        подкреплением (Reinforcement Learning). Ему не нужен датасет. По сути 
        он его на ходу собрает. В принципе, если бы человек учился неизвестному, 
        то он бы тоже делел случайные ходы и смотрел чтоб будет. По сути RL это 
        статистика.
        2) Выделение закономерностей. Сеть может выделить те закономерности
        которые людьми сложно формализуемы.
        3) Устойчивость к шумам.
        4) Возможность прогнозирования.
        Недостатки.
        1) Неободимость датасета. Это касается обучение с учителем. Часто 
        применяется в классификации картинок. Для него необходим датасет. Его 
        готовят люди. Не для всех предметных областей они есть. 
        2) Невозможность вытащить сформулированные правила из обученной сети. У 
        сверточных сетей с этим проще, т к на промежуточных картах активации 
        можно увидеть, какие места на картинке оказались важными. Но карта 
        активации - это даже не картинка. Это места, где фильтр свертки дал 
        большие числа. На первых слоях будет белеберда - маленькие 
        геометрические черты картинки. Есть метод, когда обученную сеть 
        подключают на вход другой сети (transfer learning). Перенос возможен 
        только так. При этом замораживают часть сети, чтобы она не обучалась. 
        Из-за невозможности понять, почему было принято решение сложно 
        настраивать сеть. Приходится не менять ее внутренние составляющие,
        а создавать внешние условия, которые узнаются эмпирическими методиками.
        3) Не достаточно быстрая адаптация, как того может требовать окружающий 
        мир. В сравнении с аналитическими методами у сетей наблюдается большая 
        адаптивность. Это касается RL.
        4) Сложные модели требуют большого объема сетей. В статье, опять же, 
        есть пример обчения тела ходьбе с 17 степенями свободы. При увеличении 
        степеней свободы, не получатется нормально обучить. Для анализа большой 
        сети требуется еще большая сеть. Большая сеть не может работать в real 
        time и склонна к переобучению.
        5) Не все сети могут крутить циклы. Относится к RL.
        6) Не все модели сетей учитывают предыдущие состояния.
        7) Необходимость длительного времени на обученение. Обучение в данном 
        случае выделяется как отдельная фаза работы с методом. 
        8) Сложность дообучения. Обучать приходится сразу всем задачам. Иначе 
        при дообучении веса перезапишутся под новую задачу. Есть вид обучения 
        incremental learning. Он подразумевает постоянно постоянно 
        расширяющуюся модель при новых входных данных. Я не слышал об его 
        болшом распространении.
        9) Невозможность интеграции отдельных сетей в одну большую. Т к они 
        имеют разные архитекуры, абсолютные значения весов, механизмы обучения.
        В статье, описывается предположение о том, чтобы сверточные для 
        картинок, рекурентные для текста и обучение с подкреплением для 
        генерации движений использовались вместе. Даже если ону сеть 
        присоединяют  другой, то у одной из них, которая уже обучена веса 
        замораживают.
        10) Необходимость разработки архитектуры еще до начала обученя. 
        Допускаю, что есть проекты, где сеть конфигурирует архитектуру, но я 
        не видел, чтобы они получили распространение.

    3.2 Логическое программирование.

        Этот метод ИИ можно обобщить до набора ifов. Его еще часто называют 
        экспертными системами. Эксперт (человек, компетентный в предметной 
        области) составляет правила, через которые пргоняются входные данные
        и область принятия решений сужается. Иногда до конкретного решения,
        иногда до множества решений, иногда до ни одного. Часто используются 
        программные пакеты в декларативной парадигме, когда программисту
        необходимо правильно формировать запросы, а программа сама решает в 
        какой последовательности производить вычисления.
        Достоинства.
        1) Это точный метод, при одинаковых входных условиях будет один и 
        тот же результат.
        Процесс принятия конкретного решеня можно проследить, что легло в 
        его основу и почему оно было принято.
        2) Опыт накопленный специалистами легоко передается машине, 
        через добавление новых условий и корректировки имеющихся.
        Отсутсвует фаза обучения.
        3) Вывод новых решений, которые ранее не были записаны в память.
        Недостатки.
        1) Экспертная система требует постоянного обновления своей базы 
        знаний.
        2) Неумение выявлять новые неизвестные ситуации, не описанные правилами.
        3) Отсутсвие самообучения.

    3.3 Нечеткая логика

        Может являтся определенной надстройкой к логическому программированию.
        Некоторые авторы выделяют ее в отдельный метод. Добавляет возможность
        дробного значения выраженности признака. Не true или false, а например 
        0.3. Для работы над признаками требуются доработаннные операторы. Чать 
        признаков наследуется от логического программирования.
        Достоинства.
        1) Большая гибкость в незнакомой ситуации.
        Недостатки.
        2) Нечеткие системы не дают точных ответов. Связано с ковертацией
        типов данных из дробных в целые.

    3.4 Генетические алгоритмы

        Решение делится на признаки. Признаки комбинируются в соответсвтвии с 
        законами генетики и эволюции. Условные особи (решений с набором функций)
        виживают в том случае, если оказались наиболее результативны по 
        сравнению с другими решениями. Далее они дают потомство, сочетающее в 
        себе скрещенные признаки от двух лучших решений и алгоритм повторяется.
        Достоинства.
        1) Подходит для неформализованных задач.
        2) Высокий параллелизм.
        Недостатки.
        1) Приближенный метод.
        2) Качество решения зависит от времени расчета.

    3.5 Статистические методы
    
        Предлагают вероятностные решения, когда есть статистика.
        Достоинства.
        1) Не требуют точных данных для составления выборки.
        2) Обоснованность решений.
        3) Простота в эксплуатации.
        Недостатки.
        1) Необходима длинная статистическая выборка.
        2) Решение принимается не в зависимости от состояния объекта, а от 
        истории выборки.
        3) Не работают без шаблона типичного поведения.

    3.6 Ассоциативная память

        Находил данный метод в одной из книжек. Плохо в нем разобрался.
        https://disk.yandex.ru/i/MfLZAhqC4lK66g
        Достоинства.
        1) Самоорганизующаяся система.
        2) Адаптируется к изменениям.
        Недостатки.
        1) Необходима обучающая выборка.

    3.7 Сигнатурные методы

        Часто применяются на текущий момент. Заключаются в сравнении входных 
        признаков с распространенными шаблонами принятия решений.

    3.8 Выводы

        Руководствуясь целью создания сильного ИИ, можно сформулировать 
        требования к методу на которм он может быть построен. Возьмем за 
        эталон поведение людей в бытовой обстановке. Производя сравнение с 
        человеком, выделим черты которыми искомый метод не должен обладать.
        1) Невозможность объяснения решения. 
        Если использовать методы с данной черотй, трудно будет понять как 
        настраивать систему на работоспособность, кроме как экспериментальным 
        методом. В противном случае, придется создавать систему объяснения 
        решений, которая может быть больше и сложнее, чем сама исследуемая 
        система. Понимать почему метод принял то или иное решение - жизненно 
        необходимо, для дальнейшей его настройки. Выделился термин - объяснимый 
        ИИ (explainable AI). Вспоминается проект гугла.
        https://cloud.google.com/explainable-ai/
        Судя по картинке, они как раз показывают промежуточные слои сверточной 
        сети, хотя, я сильно не вчитывался. Как минимум важен факт выделения 
        термина, заинтерисованности гугла. Есть проекты изъятия правил из сети 
        в виде математики. Это опять же предназначено для человека. Люди могут 
        объяснить, по какой причине было принято то или иное решение.
        2) Неточность принимаемого решения. 
        Решение необходимое для результата может содержаться в нерассмотренной 
        области. Людьми решение принимается в сжатые сроки. После определенного 
        количества метаний, люди принимают хоть какое-то решение и дальше 
        действуют по обстоятельствам. Это отчасти связано со сложностью 
        обработки аналитических алгоритмов в сознании человека. Вспоминается 
        проблема вагонетки и в данном случае сводится к случайному выбору. На 
        компьютере легко обрабатываются большие алгоритмы, которые не умещаются 
        в оперативной памяти человека и люди в таких случаях пользуются 
        бумажками для записей.
        3) Необходимость обучающей выборки. 
        Она может быть недостаточно объемна и на ее подготовку нужны ресурсы. У 
        человека обучение происходит за короткие сроки. Исчесляется еденицами 
        предложений или еденицами попыток действий. Большинство бытовых задачь 
        решаемых человеком уже понятно как делать и нужно только объяснить 
        машине как их делать. По крайней мере так мы поступаем с детьми. 
        Человек учится на длине датасета 1 ну может быть 10. Датасеты 
        однозначное зло. Часть опыта у людей передается по наследству, но это 
        связано скорее с управлением организмом. Часть передается с воспитанием 
        и длится порядка 20 лет. С учетом накопленного опыта дообучение может 
        происходить буквально в пару предложений. Подитожим. Нейронные сети 
        имеют весомые достоинства, но их нельзя применить из-за необходимости 
        датасетов и отсутсвия видимости процесса приянятия решения. 
        Ассоциативной памяти и статистическим  алгоритмам тоже нужна выборка. 
        Генетические алгоритмы — не могут объяснить решение и являются 
        приближенным методом. Сигнатурные методы и ЛП нуждаются в постоянном 
        обновлении базы и не адаптивные. В качестве основы предлагается выбрать 
        логическое программирование. Оно дает обоснованность решений, выдачей 
        применимых правил. Принимает решение точно, так как основывается на 
        опыте экспертов. Не нуждается в большой обучающей выборке, так как 
        правила будут емко содержать законы предметной области. После выбора 
        центрального метода хочется воспользоваться гибридным подходом и 
        использовать другие методы либо как отдельные библиотеки ели они 
        архитектурно по разному работают, либо вышить внутрь как нечеткая логика 
        наприимер. Если применять вместе, будут отдельные подсистемы, вывод 
        которых опять придется объединять, отдавая чему-то предпочтение. В то же 
        время список не большой, всего 7 пунктов. Но данный способ гибидизации 
        уже наверняка описан в литературе и сохраняет имеющиеся недостатки этих 
        методов. После узневания недостатков данных методов, я стал меньше 
        внимания им уделять, хотя все равно слежу за новостями в их сфере.

4.0 Предлагаемое решение

    Многие, наверняка, слышали про обработку естественного языка.
    Есть дисциплина - вычислительная лингвистика. В ней выработн ряд приемов, для удобной работ с языками.
    Именно язык я считаю основным атрибутом интеллекта. Через язык можно понть какие конструкции выстраиваются в сознании у интеллектуального агента, получить обратную связь.
    Даже если отпросить комуникативную функцию языыка, мышелние все равно, частично производится на нем.
    Часть дальнейших утверждений я услышал от своего научного руководителя в вузе - Курушина Даниила Сергеевича, к.т.н ПНИПУ.
    https://pstu.ru/basic/glossary/staff/?sid=557
    Часть его утверждений я, изменил или перефразировал.
    1) Семантический треугольник.
    2) Подмена понятий, гибкий формат хранения. Мама мыла раму.
    3) Графовая структура. Операции сравнеиния с частю грфава. Мульиязычность. онтология
    4) Накладываем ЛП. Пайдаталог.
    



    Есть определенная черта, на которую я обратил внимание, которая как мне кажется может хранить в себе все методы в определенной форме.
    И может переключаться между методами если их недостатки китичны.


    при добавлении языка мы исправим недостатки ЛП и возьмем преимущества остальных методов.

    Мышление человека может вулючать отдельные элементы перечисленных методов в неизвестно какой комбинации.
    
    Используя язык мы приобретаем ряд преимуществ по сравнению с языками высокого 
    уровня при написании программ.

    Например, удобно писать рекурсивные функции, выход из которых и условия проваливания pyDatalog контролирует сам, не нагружая программиста.
    Обеспечивается более высокий уровень абстракции и человеку проще переводить свои мысли в инструкции для машины и контролировать ход выполнения программы.

    Перескачить на следующий раздел.
    

    С помощью языка объяснить остальные методы и использовать из по возможности.
    В том числе и описать саом ЛП.
    По аналогии как люди, работая на ДНК поняли как оно работает. Я не биолог но условно.





    графовый компьютер

    тз в предложение включить

    Посмотреть можно ли дополнить тз этими свойсвтами
    https://en.wikipedia.org/wiki/Artificial_general_intelligence
    https://ru.wikipedia.org/wiki/Сильный_и_слабый_искусственные_интеллекты