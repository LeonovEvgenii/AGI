0.0 Целевая аудитория

    ???

1.0 Определение

    Существует классификация деления ИИ на сильный и слабый.
    Начнем со слабого. Его еще "узким" называют. Процитирую определение.
    "Artificial Narrow Intelligence (ANI): это ИИ специализирующийся на 
    конкретной задаче/проблеме. И, зачастую, превосходящий человека в 
    решении этой задачи. Например, шахматная программа обыграла человека, но 
    она умеет только это. Речь идёт о различного рода экспертных системах, 
    как правило, работающих с большими объёмами данных." Определние сильного ИИ. 
    Это программа, обладающая рядом обязательных черт или свойств: память, 
    целеполагание, принятие решения, планирование, вывод новых знаний, 
    общение. Позже, допускаю, что могут быть добавлены черты или изменены 
    существующие. Оять же есть множество источников, где его 
    пытаются дать. Его же иногда называют общим. Artificial General 
    Intelligence (AGI).

2.0 Актуальность

    Сейчас существет много тел роботов, которые обладают достаточно продвинутой 
    механикой для решения общих задач. Но отсутвие сегмента программ сильного ИИ 
    не позволяет им выполнять эти задачи. Их программы часто базируются на 
    автоматах и не подразумевают большой изменичивости или дообучения на ходу.
    Посмотрим несколько примеров. Бостон динамикс объявила о желании создания 
    подразделения, занимающегося вопросами ИИ. Еще раз констатировала, что 
    атлас всего лишь научный инструмент и тацует по заранее заложенной 
    программе. Четкое выделение предметных областей в будущей разработке, 
    скорей всего приведет к "слабому" ии.
    https://www.youtube.com/watch?v=InvCCX4W8_Y
    еще один пример. Проект google everyday. его создатели подчеркивают, как я 
    понял, сложность решения бытовых задачь. Они пытаются собрать робота из 
    общесдоступных комплектующих.
    https://everydayrobots.com/
    Многие другие компании (например toyota) пыталась делать антропоморфного 
    помошника для дома, но возможности этих роботв далеки от человека.
    Думаю, что проблема актуальна.

3.0 Текущие подходы

    Рассмотрим несколько методов приянтия решений в ИИ, их достоинства и недостатки.

    3.1 Нейросетевые методы
        Пояснять, как работают данные методы не буду в виду их популярности.
        Были рассмотерны статьи.
        https://habr.com/ru/post/468379/
        https://habr.com/ru/company/neurodatalab/blog/335238/
        https://habr.com/ru/post/437020/
        Достоинства.
        1) Отсутсвие датасета для определенных видов сетей. Касается обучения с 
        подкреплением (Reinforcement Learning). Ему не нужен датасет. По сути 
        он его на ходу собрает. В принципе, если бы человек учился неизвестному, 
        то он бы тоже делел случайные ходы и смотрел чтоб будет. По сути RL это 
        статистика.
        2) Выделение закономерностей. Сеть может выделить те закономерности
        которые людьми сложно формализуемы.
        3) Устойчивость к шумам.
        4) Возможность прогнозирования.
        Недостатки.
        1) Неободимость датасета. Это касается обучение с учителем. Часто 
        применяется в классификации картинок. Для него необходим датасет. Его 
        готовят люди. Не для всех предметных областей они есть. 
        2) Невозможность вытащить сформулированные правила из обученной сети. У 
        сверточных сетей с этим проще, т к на промежуточных картах активации 
        можно увидеть, какие места на картинке оказались важными. Но карта 
        активации - это даже не картинка. Это места, где фильтр свертки дал 
        большие числа. На первых слоях будет белеберда - маленькие 
        геометрические черты картинки. Есть метод, когда обученную сеть 
        подключают на вход другой сети (transfer learning). Перенос возможен 
        только так. При этом замораживают часть сети, чтобы она не обучалась. 
        Из-за невозможности понять, почему было принято решение сложно 
        настраивать сеть. Приходится не менять ее внутренние составляющие,
        а создавать внешние условия, которые узнаются эмпирическими методиками.
        3) Не достаточно быстрая адаптация, как того может требовать окружающий 
        мир. В сравнении с аналитическими методами у сетей наблюдается большая 
        адаптивность. Это касается RL.
        4) Сложные модели требуют большого объема сетей. В статье, опять же, 
        есть пример обчения тела ходьбе с 17 степенями свободы. При увеличении 
        степеней свободы, не получатется нормально обучить. Для анализа большой 
        сети требуется еще большая сеть. Большая сеть не может работать в real 
        time и склонна к переобучению.
        5) Не все сети могут крутить циклы. Относится к RL.
        6) Не все модели сетей учитывают предыдущие состояния.
        7) Необходимость длительного времени на обученение. Обучение в данном 
        случае выделяется как отдельная фаза работы с методом. 
        8) Сложность дообучения. Обучать приходится сразу всем задачам. Иначе 
        при дообучении веса перезапишутся под новую задачу. Есть вид обучения 
        incremental learning. Он подразумевает постоянно постоянно 
        расширяющуюся модель при новых входных данных. Я не слышал об его 
        болшом распространении.
        9) Невозможность интеграции отдельных сетей в одну большую. Т к они 
        имеют разные архитекуры, абсолютные значения весов, механизмы обучения.
        В статье, описывается предположение о том, чтобы сверточные для 
        картинок, рекурентные для текста и обучение с подкреплением для 
        генерации движений использовались вместе. Даже если ону сеть 
        присоединяют  другой, то у одной из них, которая уже обучена веса 
        замораживают.
        10) Необходимость разработки архитектуры еще до начала обученя. 
        Допускаю, что есть проекты, где сеть конфигурирует архитектуру, но я 
        не видел, чтобы они получили распространение.

    3.2 Логическое программирование.

        Этот метод ИИ можно обобщить до набора ifов. Его еще часто называют 
        экспертными системами. Эксперт (человек, компетентный в предметной 
        области) составляет правила, через которые пргоняются входные данные
        и область принятия решений сужается. Иногда до конкретного решения,
        иногда до множества решений, иногда до ни одного. Часто используются 
        программные пакеты в декларативной парадигме, когда программисту
        необходимо правильно формировать запросы, а программа сама решает в 
        какой последовательности производить вычисления.
        Достоинства.
        1) Это точный метод, при одинаковых входных условиях будет один и 
        тот же результат.
        Процесс принятия конкретного решеня можно проследить, что легло в 
        его основу и почему оно было принято.
        2) Опыт накопленный специалистами легоко передается машине, 
        через добавление новых условий и корректировки имеющихся.
        Отсутсвует фаза обучения.
        3) Вывод новых решений, которые ранее не были записаны в память.
        Недостатки.
        1) Экспертная система требует постоянного обновления своей базы 
        знаний.
        2) Неумение выявлять новые неизвестные ситуации, не описанные правилами.
        3) Отсутсвие самообучения.

    3.3 Нечеткая логика

        Может являтся определенной надстройкой к логическому программированию.
        Некоторые авторы выделяют ее в отдельный метод. Добавляет возможность
        дробного значения выраженности признака. Не true или false, а например 
        0.3. Для работы над признаками требуются доработаннные операторы. Чать 
        признаков наследуется от логического программирования.
        Достоинства.
        1) Большая гибкость в незнакомой ситуации.
        Недостатки.
        2) Нечеткие системы не дают точных ответов. Связано с ковертацией
        типов данных из дробных в целые.

    3.4 Генетические алгоритмы

        Решение делится на признаки. Признаки комбинируются в соответсвтвии с 
        законами генетики и эволюции. Условные особи (решений с набором функций)
        виживают в том случае, если оказались наиболее результативны по 
        сравнению с другими решениями. Далее они дают потомство, сочетающее в 
        себе скрещенные признаки от двух лучших решений и алгоритм повторяется.
        Достоинства.
        1) Подходит для неформализованных задач.
        2) Высокий параллелизм.
        Недостатки.
        1) Приближенный метод.
        2) Качество решения зависит от времени расчета.

    3.5 Статистические методы
    
        Предлагают вероятностные решения, когда есть статистика.
        Достоинства.
        1) Не требуют точных данных для составления выборки.
        2) Обоснованность решений.
        3) Простота в эксплуатации.
        Недостатки.
        1) Необходима длинная статистическая выборка.
        2) Решение принимается не в зависимости от состояния объекта, а от 
        истории выборки.
        3) Не работают без шаблона типичного поведения.

    3.6 Ассоциативная память

        Находил данный метод в одной из книжек. Плохо в нем разобрался.
        https://disk.yandex.ru/i/MfLZAhqC4lK66g
        Достоинства.
        1) Самоорганизующаяся система.
        2) Адаптируется к изменениям.
        Недостатки.
        1) Необходима обучающая выборка.

    3.7 Сигнатурные методы

        Часто применяются на текущий момент. Заключаются в сравнении входных 
        признаков с распространенными шаблонами принятия решений.

    3.8 Выводы

        Руководствуясь целью создания сильного ИИ, можно сформулировать 
        требования к методу на которм он может быть построен. Возьмем за 
        эталон поведение людей в бытовой обстановке. Производя сравнение с 
        человеком, выделим черты которыми искомый метод не должен обладать.
        1) Невозможность объяснения решения. 
        Если использовать методы с данной черотй, трудно будет понять как 
        настраивать систему на работоспособность, кроме как экспериментальным 
        методом. В противном случае, придется создавать систему объяснения 
        решений, которая может быть больше и сложнее, чем сама исследуемая 
        система. Понимать почему метод принял то или иное решение - жизненно 
        необходимо, для дальнейшей его настройки. Выделился термин - объяснимый 
        ИИ (explainable AI). Вспоминается проект гугла.
        https://cloud.google.com/explainable-ai/
        Судя по картинке, они как раз показывают промежуточные слои сверточной 
        сети, хотя, я сильно не вчитывался. Как минимум важен факт выделения 
        термина, заинтерисованности гугла. Есть проекты изъятия правил из сети 
        в виде математики. Это опять же предназначено для человека. Люди могут 
        объяснить, по какой причине было принято то или иное решение.
        2) Неточность принимаемого решения. 
        Решение необходимое для результата может содержаться в нерассмотренной 
        области. Людьми решение принимается в сжатые сроки. После определенного 
        количества метаний, люди принимают хоть какое-то решение и дальше 
        действуют по обстоятельствам. Это отчасти связано со сложностью 
        обработки аналитических алгоритмов в сознании человека. Вспоминается 
        проблема вагонетки и в данном случае сводится к случайному выбору. На 
        компьютере легко обрабатываются большие алгоритмы, которые не умещаются 
        в оперативной памяти человека и люди в таких случаях пользуются 
        бумажками для записей.
        3) Необходимость обучающей выборки. 
        Она может быть недостаточно объемна и на ее подготовку нужны ресурсы. У 
        человека обучение происходит за короткие сроки. Исчесляется еденицами 
        предложений или еденицами попыток действий. Большинство бытовых задачь 
        решаемых человеком уже понятно как делать и нужно только объяснить 
        машине как их делать. По крайней мере так мы поступаем с детьми. 
        Человек учится на длине датасета 1 ну может быть 10. Датасеты 
        однозначное зло. Часть опыта у людей передается по наследству, но это 
        связано скорее с управлением организмом. Часть передается с воспитанием 
        и длится порядка 20 лет. С учетом накопленного опыта дообучение может 
        происходить буквально в пару предложений. Подитожим. Нейронные сети 
        имеют весомые достоинства, но их нельзя применить из-за необходимости 
        датасетов и отсутсвия видимости процесса приянятия решения. 
        Ассоциативной памяти и статистическим  алгоритмам тоже нужна выборка. 
        Генетические алгоритмы — не могут объяснить решение и являются 
        приближенным методом. Сигнатурные методы и ЛП нуждаются в постоянном 
        обновлении базы и не адаптивные. В качестве основы предлагается выбрать 
        логическое программирование. Оно дает обоснованность решений, выдачей 
        применимых правил. Принимает решение точно, так как основывается на 
        опыте экспертов. Не нуждается в большой обучающей выборке, так как 
        правила будут емко содержать законы предметной области. После выбора 
        центрального метода хочется воспользоваться гибридным подходом и 
        использовать другие методы либо как отдельные библиотеки ели они 
        архитектурно по разному работают, либо вышить внутрь как нечеткая логика 
        наприимер. Если применять вместе, будут отдельные подсистемы, вывод 
        которых опять придется объединять, отдавая чему-то предпочтение. В то же 
        время список не большой, всего 7 пунктов. Но данный способ гибидизации 
        уже наверняка описан в литературе и сохраняет имеющиеся недостатки этих 
        методов. После узневания недостатков данных методов, я стал меньше 
        внимания им уделять, хотя все равно слежу за новостями в их сфере.

4.0 Предлагаемое решение

    Предлагается начать разработку с работы над текстом. Датасеты в виде текста
    люди начали писать еще до изобретения компьютеров и они не требуют
    больших вычеслительных ресурсов для обработки входного сигнала по сравнению 
    с кртинками, звуками, движением. Можно
    сосредоточиться именно на логике принятия решений в процессе диалогов и
    повествования. Так же именно в тексте, люди пытаются в осонвном хранить
    свои знания. Дисциплина изучающая обработку естественного языка (ЕЯ) - 
    вычислительная лингвистика. В ней выработн ряд приемов, для 
    удобной работ с языками. Работать с языком можно на разных уровнях: 
    морфемный (части слова), морфологический (части речи), ситаксис (предлжения) 
    и тд. Нас в большей степени интерисует семантический. Изучает смысловое 
    значение едениц языка. Именно язык я считаю основным атрибутом интеллекта. 
    Через язык можно понть какие конструкции выстраиваются в сознании у 
    интеллектуального агента, получить обратную связь. Даже если отбросить 
    комуникативную функцию языыка, мышелние все равно, частично производится 
    на нем. Часть дальнейших утверждений я услышал от своего научного 
    руководителя в вузе - Курушина Даниила Сергеевича, к.т.н ПНИПУ.
    https://pstu.ru/basic/glossary/staff/?sid=557
    Часть его утверждений я, изменил или перефразировал.
    1) Семантический треугольник. В его вершинах находятся слово, образ и 
    реальный объект. В оригинале используются другие обозначения, но смысл, я 
    думаю передал. Слово это набор символов, букв, знак, всте то, чем можно 
    обозначить рельный объект или объяснить собеседнику о чем идет речь. Образ 
    - это то какими знаниями, информацией обладает интелекктуальный агент об 
    описываемом реальном объекте. То как он его себе представляет. Я его могу 
    называть понятием. Реальный объект в полной степени не соответсвует 
    сохраненному образ и представляет собой объекты из окружающего мира. Данный 
    треугольник показывает одновременную связь этих трех важных компонент. Если 
    интеллектуальный агент (ИА) ошибается в суждениях, значит его образ не 
    соответсвует реальному объекту. Если два ИА не понимают друг друга, занчит 
    они, возможно, обозначают разными знаками одни и те же реальные объекты. 
    Или одним знаком разные объекты. В процессе обучения или общения за каждым 
    образом закрепляется знак или идет проверка, что он уже закреплен. Пример 
    подмены понятий. Предложение: мама мыла раму. Рама может быть оконным 
    косяком, дочкой по имени рама, самолетом времен второй мировой.
    2) Графовая структура хранения данных. Одной из проблем текущего 
    программирования является узкозаточенность под определенные форматы данных.
    В сознании человека визуалный, звуковой, текстовый, моторный, тактильный 
    образы связаны. Пример связи зрительной, и моторной. Если человеку сказать 
    нарисуй пальцм в воздух окно с закрытыми глазами, то человек обведет квадрат. 
    Может быть поставит перемычки посередине. Что бы связывать любые элементы 
    друг с другом можно использовать графы. По сути они только содержат элементы 
    и связи между ними. В современном программировании часто используются 
    реляционные базы данны. Но они содержат только определенные типы связей
    (ячейка связывает столбец со сторкой). В этом есть избыточность для 
    организации сложных зависемостей. Для организации еще одной связи придется 
    довалять новые ячейки, может быть столбцы и строки. Многие ячейки будут 
    пустыми. Еще они не наглядны. В графе, думаю, можно представлять даже 
    картинки и звуковые дорожки. Тут уже графовые формы хранения явлются не 
    удобными, т к сложных зависимостей не предвидится. Но для унификации или 
    эксперемента, можно попробовать все представлять в графе. Особенно 
    удобно на графе хранить семантическую структуру текста. Теперь представим, 
    что все образы или понятия хранящиеся в сознании образуют граф. Для понятия 
    используют термин денотат, поэтому в литературе можно найти по формулировке
    денотатный граф. Граф пополняется новыми вершинами и связями из текстовых 
    предложений, которые поступаю на вход системе (кодируются знаками).
    3) Операции над грфами. Выделю две наиболее важные операции на графами. 
    Первое сравнение части части графа с каким-то другим меньшим графом. Второе 
    - поиск в графе. С помощю первого можно совершать автоматические переводы. 
    Когда граф образованный с помощью одной системы знаков сравнивается с графом 
    образованным другой системой знаков. После нахождения общих частей, можно 
    сказать что перевод или понимание ситуации верное. Я слышал об онтологиях, 
    как о формате хранения данных. Подмечу, что стрелки там подписываются и 
    обозначают глаголы. 
    https://protege.stanford.edu/
    Есть специализированные компьютеры для работ на графами.
    https://habr.com/ru/news/t/669916/
    4) Хранение и использование знаний. Одним из важных свойств языка является 
    вывод определений. Выделю два типа определения. Первое, когда из более 
    простых известны слов выводятся новые более сложные и узкоспециализированные 
    путем выстраивания комбинаций. Второе - формирование правила на основе 
    последовательности повторяющихся действий. Допускаю, что их можно 
    гибридизировать. Предлагается внутри некоторых вершин графа распологать код 
    на обычном языке программирования, которые берут показания от датчиков 
    (аналог органов чувств). Так же предлагается собирать определения некоторых 
    понятий в виде подграфа, в котором в свою очередь содержатся вышеописанные 
    вершины. Назову это определениями первого рода. Определения второго рода уже 
    не содержат кода, а описываются другими вершинами (понятиями). Новые 
    определения могут вводиться на естественном языке с собеседником или 
    выводиться для удобства обозначения. Каждое определение это программа, 
    которая запускает все слова, которые в нем содержатся для его описания. 
    Слова используемые для описания, тоже в свою очередь являются программами. 
    Руководствуясь данной концепцией можно на естественном языке записыват 
    алгоритмы. Вспоминаются перечисленные методы ИИ в разделе 3. Их можно 
    попробовать реализовать на языковой схеме. Используя естественный язык (ЕЯ) 
    мы приобретаем ряд преимуществ по сравнению с языками програмирования (ЯП) 
    при написании программ. Обеспечивается более высокий уровень абстракции и 
    человеку проще переводить свои мысли в инструкции для машины и 
    контролировать ход выполнения программы. Так же можно описать собственную 
    работу. По аналогии как люди, работая на ДНК поняли как оно работает. Я не 
    биолог, но условно.
    5) Формирование целей. На понятном системе языке можно формировать цели.
    То есть использовать, только те слова, которые она уже знает.
    6) Запись последовательности событий. Назову это историями. Может 
    представлять из себя граф, где элементы сслыаются друг на друга сохраняняя
    последовательность во времени.
    7) Высокоуровневые понятия. Будет проще реализовать такие определения как
    чувства, социальные паттерны и т п, когда будут реализованы более простые 
    определения. Данный процесс обучения отличается от обучения неросетей.
    Но должен дать более гибко-настраиваемую систему. Изменение настроек 
    предпологается вностить на все том же ЕЯ.
    8) Вопросы и ответы. Вопрос системы к другому ИА представляет собой вызов
    функций и его памяти и сравнение со своей памятью. И наоборот, обращение
    к системе представляет последовательный вызов кода понятий с возможнвм
    рекурсивным проваливанием и выдачей ответв в виде результата работы или
    обрбаботки этим перечнем понятий.
    9) локальная и глобальная память. При диалоге все понятия записываются
    в локальную память. При завершении диалога, при находжении новых понятий и 
    факта совершения диалога идет сапись в глобальную память.

5.0 

    Для себя я составил документ TZ.txt. Он содержи в более формальном виде мысли 
    раздела 4. При этом он хуже отредактирован. Так же есть локальный документ 
    rassuzdnie.txt в котором идет локальное проектирование. Сейчас я пытаюсь 
    собрать небольшую иллюстарцию. Небольшой диалог с программой, в которм 
    демонстрируется грфовая форма хранения, создание и использование нового 
    определения.